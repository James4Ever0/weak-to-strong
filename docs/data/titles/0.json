{
    "/README.md": "Weak-to-Strong Binary Classification Codebase",
    "/README.md:1-11": "Weak-to-Strong Learning Setup for Binary Tasks",
    "/README.md:13-44": "Setting Up and Running the Project",
    "/README.md:46-60": "Contributors, License, and Acknowledgments",
    "/notebooks/Plotting.py": "Labeled Plot Calculation",
    "/notebooks/Plotting.py:1-47": "Seaborn Plotting Setup",
    "/notebooks/Plotting.py:111-114": "Labeling and Saving Plots",
    "/notebooks/Plotting.py:47-66": "Accuracy Grouping and Storage",
    "/notebooks/Plotting.py:67-81": "Weak-Strong Model Accuracy Assignments",
    "/notebooks/Plotting.py:82-98": "DataFrame Melting and Plotting Operations",
    "/notebooks/Plotting.py:98-110": "Accuracy Analysis and PGR Table",
    "/pyproject.toml": "Build System and Dependencies for \"weak_to_strong\" Python Project",
    "/setup.py": "Setting Up Python Package with Setuptools",
    "/train_weak_to_strong.py": "Strong to Weak: Transfer Learning Comparison",
    "/train_weak_to_strong.py:1-33": "Train Weak to Strong: Dataset and Model Training",
    "/train_weak_to_strong.py:103-138": "Transfer Learning Model Configurations",
    "/train_weak_to_strong.py:139-166": "Transfer Learning: Code for Training Weak to Strong Models",
    "/train_weak_to_strong.py:167-195": "Model Size Validation and Configuration",
    "/train_weak_to_strong.py:197-225": "Train Model with Dataset Splitting",
    "/train_weak_to_strong.py:225-249": "Training Weak to Strong AI Models",
    "/train_weak_to_strong.py:250-279": "Weak to Strong Model Training",
    "/train_weak_to_strong.py:280-307": "Transfer Loss Training in Weak to Strong Modeling",
    "/train_weak_to_strong.py:308-336": "Strong Model Transfer Learning and Performance Evaluation",
    "/train_weak_to_strong.py:337-356": "JSON Transfer Accuracy Storage",
    "/train_weak_to_strong.py:34-72": "Model Configurations List",
    "/train_weak_to_strong.py:73-102": "Dynamic Model Configurations",
    "/vision/README.md": "Weak-to-Strong Learning on ImageNet",
    "/vision/README.md:1-24": "Linear Probes on DINO for Weak-to-Strong Transfer",
    "/vision/README.md:25-50": "Weak & Strong Model Training Code",
    "/vision/README.md:51-56": "Model Accuracy Comparison",
    "/vision/data.py": "ImageNet Dataset Transformation Pipeline",
    "/vision/models.py": "Deep Learning Models Compatibility",
    "/vision/run_weak_strong.py": "Weak-Strong Label Training",
    "/vision/run_weak_strong.py:1-41": "Obtain Model Embeddings: Vision Task",
    "/vision/run_weak_strong.py:103-130": "Weak-Strong Model Training Process",
    "/vision/run_weak_strong.py:131-150": "Weak to Strong Label Accuracy Evaluation",
    "/vision/run_weak_strong.py:151-156": "Equivalent Weak-Strong Printing",
    "/vision/run_weak_strong.py:42-73": "Training Logistic Regression with Adam and Cosine Annealing",
    "/vision/run_weak_strong.py:74-102": "Epoch Looping and Model Training Accuracy",
    "/weak_to_strong/common.py": "Tokenizer and Memory Clearing in /weak_to_strong/common.py",
    "/weak_to_strong/common.py:1-40": "PyTorch Memory Cleanup & Tokenizer",
    "/weak_to_strong/common.py:41-48": "Exception Handling and Tensor Checking in Garbage Collector",
    "/weak_to_strong/datasets.py": "Dataset Config Class Creation",
    "/weak_to_strong/datasets.py:1-35": "Dataset Configurations and Loading",
    "/weak_to_strong/datasets.py:110-143": "Datasets Loaders and Formatters",
    "/weak_to_strong/datasets.py:144-182": "Loading and Preparing Datasets",
    "/weak_to_strong/datasets.py:36-67": "Preparing Datasets for Training",
    "/weak_to_strong/datasets.py:68-109": "Datasets Formatting & Registration",
    "/weak_to_strong/eval.py": "Evaluating Model Accuracy Efficiently",
    "/weak_to_strong/eval.py:1-36": "Evaluate Model Accuracy",
    "/weak_to_strong/eval.py:37-62": "Model Evaluation and Results Creation",
    "/weak_to_strong/eval.py:63-69": "Accuracy and Standard Deviation Calculator",
    "/weak_to_strong/logger.py": "WandbLogger: Weights & Biases Interaction",
    "/weak_to_strong/logger.py:1-41": "Wandb Logger with JSONL Appender",
    "/weak_to_strong/logger.py:43-86": "WandbLogger: Configurable, Multi-Instance Logging Class",
    "/weak_to_strong/logger.py:89-92": "Shutdown and Reset Logger",
    "/weak_to_strong/loss.py": "Loss Function Base Class",
    "/weak_to_strong/loss.py:1-42": "Custom Loss Functions in Weak-to-Strong Learning",
    "/weak_to_strong/loss.py:105-108": "Weighted Cross Entropy Loss",
    "/weak_to_strong/loss.py:43-73": "Custom Loss Function for Log Confidence",
    "/weak_to_strong/loss.py:75-104": "Weak-Strong Loss Function",
    "/weak_to_strong/model.py": "Transformer Model with Linear Head",
    "/weak_to_strong/model.py:1-33": "Transformer Model with Linear Head",
    "/weak_to_strong/model.py:35-60": "Gradient Checkpointing and Model Logits",
    "/weak_to_strong/train.py": "Comprehensive AI Training and Optimization",
    "/weak_to_strong/train.py:1-42": "Model Training Function",
    "/weak_to_strong/train.py:123-152": "Training Model: Loss, Accuracy, Optimizer",
    "/weak_to_strong/train.py:153-186": "Saving and Training AI Models",
    "/weak_to_strong/train.py:187-210": "Sharded Checkpoint Loading and Model Retraining",
    "/weak_to_strong/train.py:211-236": "Model Configuration and Training Setup",
    "/weak_to_strong/train.py:237-266": "Model Evaluation and Training with Time Tracking",
    "/weak_to_strong/train.py:267-292": "Saving Model and Results, Logging Accuracy, Cleaning Memory",
    "/weak_to_strong/train.py:294-294": "Test and Inference Results",
    "/weak_to_strong/train.py:43-71": "Model Initialization and Configuration",
    "/weak_to_strong/train.py:72-94": "Optimizer Initializer with Learning Rate Scheduler",
    "/weak_to_strong/train.py:95-121": "Gradient Checkpointing, Dropout Training, Mean Accuracy"
}
{
    "summary": "The code experiments with weak-to-strong learning on ImageNet using AlexNet, DINO ResNet50 and ViT-B/8 as models, providing options for data path, batch size, seed, and training parameters, while the table shows accuracy values of these models on the task and instructions to add customizations.",
    "details": [
        {
            "comment": "This code provides a simple weak-to-strong experiment on ImageNet using an AlexNet model pretrained on ImageNet as weak labels and linear probes on top of DINO models as strong students. It includes instructions for data path, weak model name, batch size, seed, number of epochs, learning rate, and number of training samples.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/vision/README.md\":0-23",
            "content": "# A Simple Weak-to-Strong Experiment on ImageNet\nWe provide code for a simple weak-to-strong experiment on ImageNet. \nWe generate the weak labels using an [AlexNet](https://pytorch.org/vision/main/models/generated/torchvision.models.alexnet.html) model pretrained on ImageNet and we use linear probes on top of [DINO](https://github.com/facebookresearch/dino) models\nas a strong student. \nThe full training command:\n```bash\npython3 run_weak_strong.py \\\n    data_path: <DATA_PATH> \\\n    weak_model_name: <WEAK_MODEL>\\\n    strong_model_name: <STRONG_MODEL> \\\n    batch_size <BATCH_SIZE> \\\n    seed <SEED> \\\n    n_epochs <N_EPOCHS> \\\n    lr <LR> \\\n    n_train <N_TRAIN>\n```\nParameters:\n* ```DATA_PATH``` &mdash; path to the base directory containing ImageNet data, see [torchvision page](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageNet.html) for instructions; should contain files `ILSVRC2012_devkit_t12.tar.gz` and `ILSVRC2012_img_val.tar`\n* ```WEAK_MODEL``` &mdash; weak model name:\n    - `\"alexnet\"` is the only default model and the only one currently implemented"
        },
        {
            "comment": "This code defines various parameters for training a weak model and a strong model, with options for different models such as ResNet50 and ViT-B/8. It also provides example commands to run the training for each model and includes information about expected results.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/vision/README.md\":24-49",
            "content": "* ```STRONG_MODEL``` &mdash; weak model name:\n    - `\"resnet50_dino\"` (default)\n    - `\"vitb8_dino\"`\n* ```BATCH_SIZE``` &mdash; batch size for weak label generation and embedding extraction (default: `128`)\n* ```SEED``` &mdash; random seed for dataset shuffling (default: `0`)\n* ```EPOCHS``` &mdash; number of training epochs (default: `10`)\n* ```LR``` &mdash; initial learning rate (default: `1e-3`)\n* ```N_TRAIN``` &mdash; number of datapoints used to train the linear probe; `50000 - N_TRAIN` datapoints are used as test (default: `40000`)\nExample commands:\n```bash\n# AlexNet \u2192 ResNet50 (DINO):\npython3 run_weak_strong.py --strong_model_name resnet50_dino --n_epochs 20\n# AlexNet \u2192 ViT-B/8 (DINO):\npython3 run_weak_strong.py --strong_model_name vitb8_dino --n_epochs 5\n```\nWith the commands above we get the following results (note that the results may not reproduce exactly due to randomness):\n| Model                   | Top-1 Accuracy |\n|-------------------------|----------------|\n| AlexNet                 | 56.6           |"
        },
        {
            "comment": "This table shows the accuracy of various models on the given task. It includes Dino ResNet50 and ViT-B/8, as well as AlexNet with DINO models. The accuracy values are provided for each model, and instructions are given to add custom models or datasets.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/vision/README.md\":50-55",
            "content": "| Dino ResNet50           | 64.5           |\n| Dino ViT-B/8            | 74.0           |\n| AlexNet \u2192 DINO ResNet50 | 61.9           |\n| AlexNet \u2192 DINO ViT-B/8  | 66.6           |\nYou can add new custom models to the `models.py` and new datasets to `data.py`."
        }
    ]
}
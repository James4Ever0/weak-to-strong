{
    "summary": "The code imports libraries, prepares data and models, calculates mean and median accuracy, performs plotting operations, and saves the labeled plot.",
    "details": [
        {
            "comment": "# Simple Plotting\nReading chunk 0-46: This code is importing necessary libraries, setting the seaborn style to whitegrid, and preparing a list of models to be plotted. It also loads configuration files from specified result folders, checks if the model's size is in the MODELS_TO_PLOT list, and continues only if it matches.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":0-46",
            "content": "#!/usr/bin/env python\n# coding: utf-8\n# # Simple Plotting\n# \n# In[ ]:\nRESULTS_PATH = \"../../your_sweep_results_path\"\nPLOT_ALL_SEEDS = False\n# Full sweep\nMODELS_TO_PLOT = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"Qwen/Qwen-1_8B\", \"Qwen/Qwen-7B\", \"Qwen/Qwen-14B\"]\n# Minimal sweep\n# MODELS_TO_PLOT = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\"]\n# In[ ]:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom IPython.display import display\nimport os\nimport glob\nimport json\n# In[ ]:\nrecords = []\nall_results_folders = ['/'.join(e.split('/')[:-1]) for e in glob.glob(os.path.join(RESULTS_PATH, \"**/*.results_summary.json\"), recursive=True)]\nfor result_folder in set(all_results_folders):\n    config_file = os.path.join(result_folder, \"config.json\")\n    config = json.load(open(config_file, \"r\"))\n    if config[\"strong_model_size\"] not in MODELS_TO_PLOT:\n        continue\n    if 'seed' not in config:\n        config['seed'] = 0\n    result_filename = (config[\"weak_m"
        },
        {
            "comment": "This code reads data from a JSON file, merges it into a DataFrame, groups the data by strong model size and calculates mean accuracy for each group. It also stores the accuracy lookup in a dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":46-65",
            "content": "odel_size\"].replace('.', '_') + \"_\" + config[\"strong_model_size\"].replace('.', '_') + \".results_summary.json\").replace('/', '_')\n    record = config.copy()\n    record.update(json.load(open(config_file.replace('config.json', result_filename))))\n    records.append(record)\ndf = pd.DataFrame.from_records(records).sort_values(['ds_name', 'weak_model_size', 'strong_model_size'])\n# In[ ]:\ndatasets = df.ds_name.unique()\nfor dataset in datasets:\n    cur_df = df[(df.ds_name == dataset)]\n    base_df = pd.concat([\n        pd.DataFrame.from_dict({\"strong_model_size\": cur_df['weak_model_size'].to_list(), \"accuracy\": cur_df['weak_acc'].to_list(), \"seed\": cur_df['seed'].to_list()}),\n        pd.DataFrame.from_dict({\"strong_model_size\": cur_df['strong_model_size'].to_list(), \"accuracy\": cur_df['strong_acc'].to_list(), \"seed\": cur_df['seed'].to_list()})\n    ])\n    base_accuracies = base_df.groupby('strong_model_size').agg({'accuracy': 'mean', 'seed': 'count'}).sort_values('accuracy')\n    base_accuracy_lookup = base_accuracies['accuracy'].to_dict()"
        },
        {
            "comment": "Resets the index of `base_accuracies` and `base_df`. Sets 'weak_model_size' to 'ground truth' and 'loss' to 'xent'. Assigns strong model accuracy based on weak model size. Transforms data for better analysis, drops missing values, and resets index. Assigns correct strong model accuracy. Excludes cases where weak model is better than the strong model from PGR calculation.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":66-80",
            "content": "    base_accuracies = base_accuracies.reset_index()\n    base_df.reset_index(inplace=True)\n    base_df['weak_model_size'] = 'ground truth'\n    base_df['loss'] = 'xent'\n    base_df['strong_model_accuracy'] = base_df['strong_model_size'].apply(lambda x: base_accuracy_lookup[x])\n    weak_to_strong = cur_df[['weak_model_size', 'strong_model_size', 'seed'] + [e for e in cur_df.columns if e.startswith('transfer_acc')]]\n    weak_to_strong = weak_to_strong.melt(id_vars=['weak_model_size', 'strong_model_size', 'seed'], var_name='loss', value_name='accuracy')\n    weak_to_strong = weak_to_strong.dropna(subset=['accuracy'])\n    weak_to_strong.reset_index(inplace=True)\n    weak_to_strong['loss'] = weak_to_strong['loss'].str.replace('transfer_acc_', '')\n    weak_to_strong['strong_model_accuracy'] = weak_to_strong['strong_model_size'].apply(lambda x: base_accuracy_lookup[x])\n    # Exclude cases where the weak model is better than the strong model from PGR calculation.\n    pgr_df = cur_df[(cur_df['weak_model_size'] != cur_df['strong_model_size']) & (cur_df['strong_acc'] > cur_df['weak_acc'])]"
        },
        {
            "comment": "This code is performing the following steps:\n1. It is melting a DataFrame and dropping NaN values related to 'transfer_acc'.\n2. It is replacing strings in 'loss' column.\n3. Calculating progress ratio ('pgr') based on 'transfer_acc', 'weak_acc', and 'strong_acc' columns.\n4. Iterating over different seeds (if PLOT_ALL_SEEDS is True) or a specific seed, and concatenating DataFrames for plotting.\n5. Filtering DataFrame based on the seed value.\n6. If seed is not None or there is only one unique seed in the DataFrame, performing additional plotting operations.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":81-97",
            "content": "    pgr_df = pgr_df.melt(id_vars=[e for e in cur_df.columns if not e.startswith('transfer_acc')], var_name='loss', value_name='transfer_acc')\n    pgr_df = pgr_df.dropna(subset=['transfer_acc'])\n    pgr_df['loss'] = pgr_df['loss'].str.replace('transfer_acc_', '')\n    pgr_df['pgr'] = (pgr_df['transfer_acc'] - pgr_df['weak_acc']) / (pgr_df['strong_acc'] - pgr_df['weak_acc'])\n    for seed in [None] + (sorted(cur_df['seed'].unique().tolist()) if PLOT_ALL_SEEDS else []):\n        plot_df = pd.concat([base_df, weak_to_strong])\n        seed_pgr_df = pgr_df\n        if seed is not None:\n            plot_df = plot_df[plot_df['seed'] == seed]\n            # We mean across seeds, this is because sometimes the weak and strong models will have run on different hardware and therefore\n            # have slight differences. We want to average these out when filtering by seed.\n            seed_pgr_df = pgr_df[pgr_df['seed'] == seed]\n        if seed is not None or cur_df['seed'].nunique() == 1:\n            plot_df = plo"
        },
        {
            "comment": "This code is performing the following tasks:\n1. Averages data by 'strong_model_accuracy', 'weak_model_size', and 'loss' in a given DataFrame, then resets index and sorts the result based on 'loss' and 'weak_model_size'.\n2. Prints dataset name and seed value used.\n3. Calculates median PGR (Percentage of Good Runs) for each loss category from a different DataFrame and displays it.\n4. Sets a color palette for line plots based on the number of unique 'weak_model_size' values in the plot DataFrame.\n5. Creates a dictionary to map each 'weak_model_size' value to a color from the palette, with black color for the 'ground truth' model.\n6. Draws a line plot from the plot DataFrame, using 'strong_model_accuracy' as x-axis and 'accuracy' as y-axis, grouped by 'weak_model_size' and 'loss'. The plot includes markers and has hue and style specified by their respective variables.\n7. Inserts a table in the lower right corner of the plot, displaying rounded PGR results from the previous step.\n8. Sets x-axis tick values to specific accuracy values, labeling them with their corresponding 'strong_model_accuracy' value and accuracy for each 'strong_model_size'.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":97-109",
            "content": "t_df[['strong_model_accuracy', 'weak_model_size', 'loss', 'accuracy']].groupby(['strong_model_accuracy', 'weak_model_size', 'loss']).mean().reset_index().sort_values(['loss', 'weak_model_size'], ascending=False)\n        print(f\"Dataset: {dataset} (seed: {seed})\")\n        pgr_results = seed_pgr_df.groupby(['loss']).aggregate({\"pgr\": \"median\"})\n        display(pgr_results)\n        palette = sns.color_palette('colorblind', n_colors=len(plot_df['weak_model_size'].unique()) - 1)\n        color_dict = {model: (\"black\" if model == 'ground truth' else palette.pop()) for model in plot_df['weak_model_size'].unique()}\n        sns.lineplot(data=plot_df, x='strong_model_accuracy', y='accuracy', hue='weak_model_size', style='loss', markers=True, palette=color_dict)\n        pd.plotting.table(plt.gca(), pgr_results.round(4), loc='lower right', colWidths=[0.1, 0.1], cellLoc='center', rowLoc='center')\n        plt.xticks(ticks=base_accuracies['accuracy'], labels=[f\"{e} ({base_accuracy_lookup[e]:.4f})\" for e in base_accuracies['strong_model_size']], rotation=90)"
        },
        {
            "comment": "Saving a labeled plot with a specific title, legend in upper left corner, and file name based on dataset and seed.",
            "location": "\"/media/root/Toshiba XG3/works/weak-to-strong/docs/src/notebooks/Plotting.py\":110-113",
            "content": "        plt.title(f\"Dataset: {dataset} (seed: {seed})\")\n        plt.legend(loc='upper left')\n        plt.savefig(f\"{dataset.replace('/', '-')}_{seed}.png\", dpi=300, bbox_inches='tight')\n        plt.show()"
        }
    ]
}